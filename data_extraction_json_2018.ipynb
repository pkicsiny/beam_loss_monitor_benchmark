{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, matplotlib.dates as dates, os, sys, pickle, re, glob\n",
    "from matplotlib import pyplot as plt\n",
    "import json\n",
    "import calendar\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "from ipywidgets import interact, IntSlider\n",
    "if \"./src\" not in sys.path:\n",
    "    sys.path.insert(0, \"./src\")\n",
    "from src import bcm_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path of json file\n",
    "json_path = \"Z:Desktop/json_data/webmonitor-es-bril-dipanalyzermon_old2018.json\"\n",
    "#json_path = \"C:/Users/pkicsiny/Desktop/TSC_CERN/BLM_study/json_data/webmonitor-es-bril-dipanalyzermon_old2018-short.json\"\n",
    "\n",
    "#set up output directories\n",
    "out_dir = \"Z:Desktop/json_data/json_pickles\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "plot_dir = \"Z:Desktop/json_data/json_plots\"\n",
    "os.makedirs(plot_dir, exist_ok=True)\n",
    "\n",
    "\"\"\"\n",
    "global variables\n",
    "\"\"\"\n",
    "\n",
    "#set up output dfs\n",
    "months = [str(m).zfill(2) for m in list(range(4,11))]\n",
    "cols = bcm_utils.get_column_names([24, 48],[9])\n",
    "\n",
    "#set up month intervals\n",
    "start_dates = [\"2018-{}-01T00:00:00Z\".format(m) for m in months]\n",
    "end_dates = [\"2018-{}-01T00:00:00Z\".format(str(int(m)+1).zfill(2)) for m in months]\n",
    "\n",
    "#json read parameters\n",
    "block_size = 30000\n",
    "plot_freq = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_json_data(json_line, result_dict):\n",
    "    ts = json_line['_source']['timestamp']\n",
    "    for m, start_date, end_date in zip(months, start_dates, end_dates):\n",
    "        if pd.Timestamp(ts) >= pd.Timestamp(start_date) and pd.Timestamp(ts) < pd.Timestamp(end_date):\n",
    "             result_dict[m] = result_dict[m].append(\n",
    "                pd.DataFrame([[json_line[\"_source\"][\"RunningSum9\"][i] for i in [23, 47]]],\n",
    "                           columns=cols,\n",
    "                           index=[ts]))\n",
    "\n",
    "                \n",
    "def read_large_file(file_handler, block_size=200):\n",
    "    block = []\n",
    "    restart_timer = True\n",
    "    for line in file_handler:\n",
    "        if restart_timer:\n",
    "            start = time.time()\n",
    "            restart_timer = False\n",
    "        block.append(line)\n",
    "        if len(block) == block_size:\n",
    "            end = time.time()\n",
    "            restart_timer = True\n",
    "            print(\"Block loaded in {} seconds\".format(end-start))\n",
    "            yield block\n",
    "            block = []\n",
    "    if block:\n",
    "        end = time.time()\n",
    "        print(\"Block loaded in {} seconds\".format(end-start))\n",
    "        yield block\n",
    "        \n",
    "\n",
    "def plot_read_progress(ax, start, idx, current_block_idx, plot_dir):\n",
    "    loop = time.time()\n",
    "    os.makedirs(plot_dir, exist_ok=True)\n",
    "    ax.scatter(idx, loop - start, c=\"b\")\n",
    "    ax.set_xlabel(\"json row index\", fontsize=19)\n",
    "    ax.set_ylabel(\"time elapsed [s]\", fontsize=19)\n",
    "    plt.title(\"json block # {}\".format(current_block_idx + 1), fontsize=20)\n",
    "    plt.savefig(plot_dir+\"/json_block_{}.png\".format(current_block_idx+1))\n",
    "    \n",
    "def utc_to_local(utc_dt):\n",
    "    # get integer timestamp to avoid precision lost\n",
    "    timestamp = calendar.timegm(utc_dt.timetuple())\n",
    "    local_dt = datetime.fromtimestamp(timestamp)\n",
    "    assert utc_dt.resolution >= timedelta(microseconds=1)\n",
    "    return local_dt.replace(microsecond=utc_dt.microsecond)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Read json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#1st version with lazy read chunks\n",
    "with open(json_path) as file_handler:\n",
    "\n",
    "#get a data by blocks, this has some additional latency\n",
    "    for current_block_idx, block in enumerate(read_large_file(file_handler, block_size=block_size)):\n",
    "        \n",
    "#set up break condition\n",
    "        if current_block_idx == 10:\n",
    "            break\n",
    "\n",
    "        print(\"Reading block: # {}\".format(current_block_idx + 1))\n",
    "\n",
    "#set up df for block data\n",
    "        result_dict = {m: pd.DataFrame() for m in months}\n",
    "\n",
    "#set up plot for block data\n",
    "        fig, ax = plt.subplots(figsize=(20, 6))\n",
    "        plt.grid()\n",
    "        plt.yticks(fontsize=13)\n",
    "        plt.xticks(fontsize=13)\n",
    "\n",
    "#start time counter\n",
    "        start = time.time()\n",
    "\n",
    "#loop over lines in block\n",
    "        for idx in range(len(block)):\n",
    "        \n",
    "#read single line\n",
    "            json_line = json.loads(block[idx])\n",
    "    \n",
    "#append row data to proper dataframe\n",
    "            get_json_data(json_line, result_dict)\n",
    "\n",
    "#make plot on performance, reading speed is around 1/300 for all ch, 1/500 for blm channels only\n",
    "            if idx%plot_freq == 0:\n",
    "                plot_read_progress(ax, start, idx, current_block_idx, plot_dir)\n",
    "            \n",
    "#save data at each block limit\n",
    "        print(\"Saving block # {}\".format(current_block_idx + 1))\n",
    "        [result_dict[m].to_pickle(out_dir+\"/month_{}_batch_{}\".format(m, current_block_idx + 1)) for m in months]\n",
    "\n",
    "#close file and plot\n",
    "        plt.close()\n",
    "    file_handler.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Read parsed json blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_blocks_path = \"Z:Desktop/json_data/json_pickles\"\n",
    "pickle_files = os.listdir(json_blocks_path)\n",
    "pickle_file_dict = {m: [pf for pf in pickle_files if \"_{}_\".format(m) in pf] for m in months}\n",
    "result_df = {m: pd.DataFrame() for m in months}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for m in months:\n",
    "    print(\"Month {}\".format(m))\n",
    "    try:\n",
    "        for idx, pf in enumerate(pickle_file_dict[m]):\n",
    "            print(\"Reading json block # {}\".format(idx+1))\n",
    "            with open(json_blocks_path+\"/\"+pf, \"rb\") as f:\n",
    "                json_block = pickle.load(f)\n",
    "                df_block = pd.DataFrame([tup[1:] for tup in json_block],\n",
    "                                        columns=[\"CH24RS9\", \"CH48RS9\"],\n",
    "                                        index=[tup[0] for tup in json_block])\n",
    "                result_df[m] = result_df[m].append(df_block)\n",
    "        result_df[m] = result_df[m].sort_index()\n",
    "        print(\"Saving pickle for month {} to {}\".format(m, out_dir))\n",
    "        result_df[m].to_pickle(out_dir+\"/pickle_{}\".format(m))\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "hours = dates.HourLocator(interval=48)\n",
    "h_fmt = dates.DateFormatter('%m/%d')\n",
    "for m in months:\n",
    "    print(\"Processing month {}\".format(m))\n",
    "    no_duplicates_df = result_df[m].drop_duplicates()\n",
    "    no_duplicates_df = no_duplicates_df/bcm_utils.γ[9]/bcm_utils.β\n",
    "    no_duplicates_df[\"new_index\"] = [np.datetime64(dt) for dt in no_duplicates_df.index.values]\n",
    "    no_duplicates_df.set_index(\"new_index\", drop=True, inplace=True)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(20, 6))\n",
    "    plt.grid()\n",
    "    \n",
    "    for ch in [24, 48]:\n",
    "    \n",
    "        # one column of dataframe\n",
    "        ch_fn_df = no_duplicates_df['CH' + str(ch) + 'RS9']\n",
    "        x = [pd.Timestamp(t) for t in ch_fn_df.index.values]\n",
    "        ax.plot(x, ch_fn_df.values, label=\"CH{}: {}\".format(ch, bcm_utils.DETECTOR_NAMES[ch][0]), linewidth=1)\n",
    "    \n",
    "        # Plot formatting\n",
    "        ax.xaxis.set_major_locator(hours)\n",
    "        ax.xaxis.set_major_formatter(h_fmt)\n",
    "        plt.yticks(fontsize=13)\n",
    "        plt.xticks(fontsize=13)\n",
    "        ax.set_title('Month {} CH 24, 48, RS 10'.format(m), fontsize=19)\n",
    "        ax.set_ylabel('Signal current (A)', fontsize=19)\n",
    "        ax.set_xlabel('Time (UTC)', fontsize=19)\n",
    "        ax.set_yscale(\"log\")\n",
    "        plt.legend(loc=\"best\", prop={'size': 13})\n",
    "    plt.savefig(\"../json_plots/2018_{}_rs10.png\".format(m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Compare with brildata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brildata = pd.read_pickle(\"../pickle_data/201810_brildata_rs10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "elasticsearch = no_duplicates_df[no_duplicates_df.index.isin(brildata.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "numrows = 200000\n",
    "ratio_bd = brildata[\"CH24RS10\"].iloc[:numrows]/brildata[\"CH48RS10\"].iloc[:numrows]\n",
    "ratio_es = elasticsearch[\"CH24RS9\"].iloc[:numrows]/elasticsearch[\"CH48RS9\"].iloc[:numrows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.grid()\n",
    "plt.plot(ratio_bd, label=\"brildata\", lw=4)\n",
    "plt.plot(ratio_es, label=\"elasticsearch\")\n",
    "plt.yticks(fontsize=13)\n",
    "plt.xticks(fontsize=13)\n",
    "plt.ylabel(\"CH24/CH48\", fontsize=19)\n",
    "plt.xlabel(\"Time\", fontsize=19)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.grid()\n",
    "plt.plot(brildata[\"CH48RS10\"], label=\"brildata (RS 10)\", lw=4)\n",
    "plt.plot(elasticsearch[\"CH48RS9\"], label=\"elasticsearch (RS 10)\")\n",
    "plt.yticks(fontsize=13)\n",
    "plt.xticks(fontsize=13)\n",
    "plt.ylabel(\"Signal current\", fontsize=19)\n",
    "plt.xlabel(\"Time\", fontsize=19)\n",
    "plt.yscale(\"log\")\n",
    "plt.legend(loc=\"upper right\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
