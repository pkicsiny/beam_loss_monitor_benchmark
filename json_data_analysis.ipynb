{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_mdggs6Wb0CD"
   },
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, matplotlib.dates as dates, seaborn as sns, paramiko, os, re, tables, glob, sys, shutil\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "from ipywidgets import interact, IntSlider\n",
    "if \"./src\" not in sys.path:\n",
    "    sys.path.insert(0, \"./src\")\n",
    "from src import bcm_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BKuRE7lmb0CG"
   },
   "source": [
    "# 0) Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2gCdTLxbb0CH"
   },
   "outputs": [],
   "source": [
    "#variables\n",
    "data_path = \"/Users/pkicsiny/sshfs/json_pickles\"\n",
    "year = 2018\n",
    "months = [str(m).zfill(2) for m in list(range(4,11))]\n",
    "rs = 10\n",
    "colnames = bcm_utils.get_column_names([24, 48],[rs])\n",
    "\n",
    "#dirs\n",
    "excel_brildata_path = \"../excel_brildata/{}\".format(year)\n",
    "excel_json_path = \"../excel_json/{}\".format(year)\n",
    "brilcalc_dir = \"../brilcalc_data/{}.csv\".format(year)\n",
    "\n",
    "#files in dirs\n",
    "excel_json_files = os.listdir(excel_json_path)\n",
    "excel_json_charge_sums = [excel_json_files[idx]for idx, i in enumerate([\"sums\" in et for et in excel_json_files]) if i]\n",
    "excel_json_charge_sum_ratios = [excel_json_files[idx]for idx, i in enumerate([\"sum_ratio\" in et for et in excel_json_files]) if i]\n",
    "excel_json_sim_data_ratios = [excel_json_files[idx]for idx, i in enumerate([\"sim_data\" in et for et in excel_json_files]) if i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J_PcoXnbb0CJ"
   },
   "source": [
    "# 1) Read monthly json pickles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KLc49E6yb0CK"
   },
   "outputs": [],
   "source": [
    "pickle_files = os.listdir(data_path)\n",
    "pickle_file_dict = {m: [pf for pf in data_path if \"_{}_\".format(m) in pf] for m in months}\n",
    "result_df = {m: pd.DataFrame() for m in months}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O8JkQikMb0CM",
    "outputId": "0679f2f4-8087-4cb8-fd96-79884d7c83d0"
   },
   "outputs": [],
   "source": [
    "for m in [\"08\"]:#months:\n",
    "    print(\"Month {}\".format(m))\n",
    "    result_df[m] = pd.read_pickle(data_path+\"/pickle_{}\".format(m))/bcm_utils.γ[9]/bcm_utils.β\n",
    "    result_df[m].index = [pd.Timestamp(ts).tz_localize(None) for ts in result_df[m].index]\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ge_rsgjub0CO"
   },
   "outputs": [],
   "source": [
    "for m in [\"08\"]: #months:\n",
    "    print(m)\n",
    "    bcm_utils.plot_blm_data(result_df[m],\n",
    "              hours=dates.HourLocator(interval=48),\n",
    "              h_fmt=dates.DateFormatter('%m/%d'), save=True)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1SChmz_Pb0CS"
   },
   "source": [
    "# 2) Read excel brildata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qnxDAtXfb0CS"
   },
   "outputs": [],
   "source": [
    "excel_df = {m: pd.DataFrame() for m in months}\n",
    "for m in months:\n",
    "    excel_df[m] = pd.read_excel(os.path.join(excel_brildata_path, \"charge_sums_2018_{}.xlsx\".format(m)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "feh-0yfcb0CV"
   },
   "outputs": [],
   "source": [
    "m = \"10\"\n",
    "print(\"From brildata:\\n\",excel_df[m][[\"CH24RS12\", \"CH48RS12\"]].sum())\n",
    "print(\"From json:\\n\",result_df[m].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KHFArJIhb0CW"
   },
   "source": [
    "# 3) Read brilcalc reference data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q5zyA6AMb0CX",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#read excel file and convert lumi data from [μb] to [b]\n",
    "brilcalc_table = pd.read_csv(brilcalc_dir, header=1)[:-3]\n",
    "brilcalc_table[\"delivered_[b]\"] = pd.to_numeric(brilcalc_table[\"delivered(/ub)\"], errors=\"coerce\")*1e6\n",
    "brilcalc_table[['run','fill']] = brilcalc_table['#run:fill'].str.split(':',expand=True)\n",
    "brilcalc_table = brilcalc_table.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pzh5X5zJb0CY"
   },
   "outputs": [],
   "source": [
    "#sum up delivered lumi per fill, used to filter hd5 files for fills that are in this table\n",
    "brilcalc_lumi_table = pd.DataFrame({\"fill\": pd.to_numeric(brilcalc_table[\"fill\"]).unique().tolist(),\n",
    "                                    \"start_time\": [pd.Timestamp(gr.iloc[0]) for gr in pd.DataFrame(brilcalc_table[\"time\"].groupby(brilcalc_table[\"fill\"]))[1]],\n",
    "                                    \"cms_delivered\": [brilcalc_table[brilcalc_table[\"fill\"] == fill][\"delivered_[b]\"].sum()\\\n",
    "                                                      for fill in brilcalc_table[\"fill\"].unique()]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0UOOzWPpb0Ca",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bcm_utils.freeze_header(brilcalc_lumi_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7RELdvcbb0Cc"
   },
   "source": [
    "# 4) Group json data by fills based on brilcalc reference times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PvpuVoD2b0Cc"
   },
   "outputs": [],
   "source": [
    "#data can cross month boundaries, always regard fill start date\n",
    "result_annual_df = pd.concat([result_df[m] for m in months])\n",
    "charge_sum_df = {m: pd.DataFrame() for m in months}\n",
    "charge_sum_error_df = {m: pd.DataFrame() for m in months}\n",
    "bl_noise_list = []\n",
    "\n",
    "excel_json_baseline = \"../baseline_noise/bl_2018.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J4DtWIWWb0Ce",
    "outputId": "8577647d-0c64-4ee9-f1a8-964a7e90142e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "baseline noise is once per month by using a sample fill which has baseline well visible in the time series\n",
    "sample fills:\n",
    "04: 6545\n",
    "05: 6699\n",
    "06: 6797\n",
    "07: 6874\n",
    "08: 7008\n",
    "09: 7151\n",
    "10: 7392\n",
    "\"\"\"\n",
    "\n",
    "brilcalc_lumi_pp = brilcalc_lumi_table[brilcalc_lumi_table[\"start_time\"] < \"2018-11-01 00:00:00\"]\n",
    "tot_len = len(brilcalc_lumi_pp)\n",
    "save_plot = False\n",
    "\n",
    "#loop over fill start dates in brilcalc df\n",
    "for idx in range(tot_len):\n",
    "    fill = brilcalc_lumi_pp[\"fill\"][idx]\n",
    "    print(\"[{}/{}] Current fill: {}\".format(idx+1, tot_len, fill))\n",
    "\n",
    "#all except the last fill\n",
    "    try:\n",
    "        fill_data = result_annual_df.loc[brilcalc_lumi_pp[\"start_time\"][idx]:brilcalc_lumi_pp[\"start_time\"][idx+1]]\n",
    "        \n",
    "#last fill\n",
    "    except:\n",
    "        fill_data = result_annual_df.loc[brilcalc_lumi_pp[\"start_time\"][idx]:]\n",
    "\n",
    "#save fill time series for baseline noise calculation\n",
    "    if fill in [6545, 6699, 6797, 6874, 7008, 7151, 7392]:\n",
    "        bl_noise_list.append(fill_data)\n",
    "        \n",
    "#sum up charge and append to df of right month\n",
    "    month = str(fill_data.index[0])[5:7]\n",
    "    print(\"Summing up collected charge.\")\n",
    "    fill_charge_sum = pd.DataFrame(fill_data.sum()).T\n",
    "    fill_charge_sum.index = [fill]\n",
    "    charge_sum_df[month] = charge_sum_df[month].append(fill_charge_sum)\n",
    "    \n",
    "#calculate stat uncertainty of charge sum\n",
    "    baseline_excel = pd.read_excel(os.path.join(excel_json_baseline), index_col=\"month\")\n",
    "    baseline_values = baseline_excel.loc[int(month)][[\"ch24\", \"ch48\"]]\n",
    "    stat_unc = pd.Series(baseline_values).rename({\"ch24\": \"CH24RS9\", \"ch48\": \"CH48RS9\"})*np.sqrt(len(fill_data))\n",
    "    #relative_unc = stat_unc/fill_data.sum()*100\n",
    "    fill_charge_sum_error = pd.DataFrame(pd.Series(stat_unc)).T\n",
    "    fill_charge_sum_error.index = [fill]\n",
    "    charge_sum_error_df[month] = charge_sum_error_df[month].append(fill_charge_sum_error)\n",
    "\n",
    "\n",
    "#make plot of fill data\n",
    "    if save_plot:\n",
    "        print(\"Saving plot of fill.\")\n",
    "        xticks = round(round(len(fill_data)/3600)/10)\n",
    "        plot_blm_data(fill_data,\n",
    "                      save=True,\n",
    "                      fill=fill,\n",
    "                      hours=dates.HourLocator(interval=max(1, xticks)),\n",
    "                      h_fmt=dates.DateFormatter('%m/%d-%Hh'))\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1v068PGwb0Cl"
   },
   "outputs": [],
   "source": [
    "#baseline noise in the two channels\n",
    "fill_noise = bl_noise_list[idx][-6000:-4000].std()*len(bl_noise_list[idx])\n",
    "fill_sum = bl_noise_list[idx].sum()\n",
    "relative_noise = fill_noise/fill_sum*100\n",
    "print(relative_noise, \"values in %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hFExLsCRb0Cm",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bcm_utils.freeze_header(charge_sum_error_df[\"04\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-iyea0S5b0Co"
   },
   "outputs": [],
   "source": [
    "#save to excel\n",
    "if not os.path.isdir(excel_json_path):\n",
    "        os.makedirs(excel_json_path, exist_ok=True)\n",
    "        \n",
    "[charge_sum_df[m].rename(columns={\"CH24RS9\":\"CH24RS10\", \"CH48RS9\":\"CH48RS10\"}).to_excel(\n",
    "    excel_json_path+\"/charge_sums_{}_{}.xlsx\".format(year, m)) for m in months]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-1JV6buRb0Cq",
    "outputId": "abfeca6c-5656-49d2-b3ca-d0ae0dc62eea"
   },
   "outputs": [],
   "source": [
    "#save stat uncertainties to excel\n",
    "if not os.path.isdir(excel_json_path):\n",
    "        os.makedirs(excel_json_path, exist_ok=True)\n",
    "        \n",
    "[charge_sum_error_df[m].rename(columns={\"CH24RS9\":\"CH24RS10\", \"CH48RS9\":\"CH48RS10\"}).to_excel(\n",
    "    excel_json_path+\"/charge_sums_stat_uncertainties_{}_{}.xlsx\".format(year, m)) for m in months]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "json_data_analysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
