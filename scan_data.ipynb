{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Found issues with hd5 files:\n",
    "- starting timestamp is 1970/01/01 (some files for 2016/09)\n",
    "- file contains fill number 0 with or without data but in the former case the data is just baseline\n",
    "- file contains non matching data for claimed fill number\n",
    "- hd5 duplicates for 2015/09 in bcml_150812-150912\n",
    "- time incontinuity: missing fills, fill parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, matplotlib.dates as dates, seaborn as sns, paramiko, os, re, sys, tables, glob, shutil\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "from ipywidgets import interact, IntSlider\n",
    "if \"./src\" not in sys.path:\n",
    "    sys.path.insert(0, \"./src\")\n",
    "import src"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mask hd5 file list for one month data where several months of data are in the same folder\n",
    "months = [str(m).zfill(2) for m in list(range(1,13))]\n",
    "\n",
    "#integrated lumi per year in inverse barns, LHC delivered nominal, from twiki, just for reference\n",
    "nominal_integrated_lumi = {2015:4.21e15, 2016:40.99e15, 2017:49.79e15, 2018:67.86e15}\n",
    "\n",
    "# longest running sum used\n",
    "rs = 10\n",
    "\n",
    "#column names for channel ratio dataframe\n",
    "charge_sum_ratio_df_columns = [\"CH5/CH1\", \"CH6/CH2\", \"CH7/CH3\", \"CH8/CH4\",\n",
    "           \"CH17/CH41\", \"CH18/CH42\", \"CH19/CH43\", \"CH20/CH44\", \n",
    "           \"CH21/CH45\", \"CH22/CH46\", \"CH23/CH47\", \"CH24/CH48\", \n",
    "           \"CH25/CH33\", \"CH26/CH34\", \"CH27/CH35\", \"CH28/CH36\", \n",
    "           \"CH29/CH37\", \"CH30/CH38\", \"CH31/CH39\", \"CH32/CH40\",\n",
    "           \"CH24/CH5\", \"CH48/CH1\", \"CH24/CH6\", \"CH48/CH2\",\n",
    "           \"CH24/CH7\", \"CH48/CH3\", \"CH24/CH8\", \"CH48/CH4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path to BCM data on /brildata\n",
    "drive = \"Z:/cmsusr/cmsnfsbrildata/brildata/bcml_18recup/bcml_181001_181031\"\n",
    "\n",
    "#find .hd5 files\n",
    "hd5_list = [filename for filename in glob.iglob(drive + '/*.hd5', recursive=True)]\n",
    "len(hd5_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read brilcalc lumi data \n",
    "Read from csv and make a dataframe with [lumi sum, fill]. Csv is exported from brilcalc and one file contains one year of lumi info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path to csv files containing exported brilcalc data for a whole year\n",
    "brilcalc_dir = \"../brilcalc_data/{}.csv\".format(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#read excel file and convert lumi data from [μb] to [b]\n",
    "brilcalc_table = pd.read_csv(brilcalc_dir, header=1)[:-3]\n",
    "brilcalc_table[\"delivered_[b]\"] = pd.to_numeric(brilcalc_table[\"delivered(/ub)\"], errors=\"coerce\")*1e6\n",
    "brilcalc_table[['run','fill']] = brilcalc_table['#run:fill'].str.split(':',expand=True)\n",
    "\n",
    "#sum up delivered lumi per fill, used to filter hd5 files for fills that are in this table\n",
    "brilcalc_lumi_table = pd.DataFrame({\"fill\": pd.to_numeric(brilcalc_table[\"fill\"]).unique().tolist(),\n",
    "                                    \"cms_delivered\": [brilcalc_table[brilcalc_table[\"fill\"] == fill][\"delivered_[b]\"].sum()\\\n",
    "                                                      for fill in brilcalc_table[\"fill\"].unique()]})\n",
    "integrated_lumi = brilcalc_lumi_table.sum()[\"cms_delivered\"]\n",
    "print(\"Integrated lumi: {:.4E}\".format(integrated_lumi), \"[b-1]\")\n",
    "print(\"Error of integrated lumi:\", (integrated_lumi - nominal_integrated_lumi[year])/(integrated_lumi)*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scan hd5 data\n",
    "Scan and read BCM detector data from /brildata on .CMS network, from hd5 files. Make a dataframe of size (#timestamps X #channel*#rs)<br>\n",
    "From the scanned data, select the fills for which there is valid lumi data (based on an exported brilcalc csv). Also select the longest running sum (12) and convert the data to current. Furthermore, drop those fills for which the data shows only the baseline, based on a predefined threshold (might as well drop fills with very little delivered lumi but that data would be more noise biased and useless anyway)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#whether or not to save output excel tables and plots\n",
    "save_output = True\n",
    "\n",
    "#output folders\n",
    "excel_out_dir = \"../excel_data_rs9/{}\".format(year)\n",
    "plot_out_dir = \"../blm_fill_images_rs9/{}\".format(year)\n",
    "if not os.path.isdir(excel_out_dir):\n",
    "        os.makedirs(excel_out_dir, exist_ok=True)\n",
    "if not os.path.isdir(plot_out_dir):\n",
    "        os.makedirs(plot_out_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#scan files month by month\n",
    "for month in months:\n",
    "\n",
    "#select hd5 files of the current month\n",
    "    file_mask = [\"_{}{}\".format(str(year)[-2:], month) in file[-24:] for file in hd5_list]\n",
    "    hd5_list_one_month = [hd5_list[i] for i in range(len(hd5_list)) if file_mask[i]]\n",
    "    no_files = len(hd5_list_one_month)\n",
    "    print(\"{} files for {}/{}\".format(no_files, year, month))\n",
    "\n",
    "#read files\n",
    "    if no_files > 0:\n",
    "        result_df, fillnum_df, fillnum_list = src.read_hd5(hd5_list_one_month, drive)\n",
    "\n",
    "#normalize with integration window length and convert from ADC to current\n",
    "        channels_data_df = result_df[src.get_column_names(range(1, 49),[rs])]/src.γ[rs - 1]/src.β\n",
    "    \n",
    "#select data based on fill number and if the fill number is found in brilcalc data\n",
    "        print(\"Filtering valid fills with nonzero delivered lumi data.\")\n",
    "        selected_fills = list(brilcalc_lumi_table[\"fill\"])\n",
    "        filtered_data_df = channels_data_df[fillnum_df[\"fill\"].isin(selected_fills)]\n",
    "        filtered_fillnum_df = fillnum_df[fillnum_df[\"fill\"].isin(selected_fills)]\n",
    "        filtered_fillnum_list = list(np.array(fillnum_list)[[fn in selected_fills for fn in fillnum_list]])\n",
    "        \n",
    "#sort data by date\n",
    "        filtered_data_df.sort_index(inplace=True)\n",
    "        filtered_fillnum_df.sort_index(inplace=True)\n",
    "        filtered_fillnum_list = sorted(filtered_fillnum_list)\n",
    "        print(\"{} valid fills found in hd5 files from {}/{}\".format(len(filtered_fillnum_list), year, month))\n",
    "        \n",
    "#make plots\n",
    "        if save_output:\n",
    "            print(\"Saving plots of data of these fills.\")\n",
    "            src.plot_fill_data(filtered_data_df,\n",
    "                               filtered_fillnum_df,\n",
    "                               filtered_fillnum_list,\n",
    "                               [1,5,24,48],\n",
    "                               out_dir=plot_out_dir+\"/{}_{}\".format(year, month), rs=rs)\n",
    "        \n",
    "#drop useless data\n",
    "        print(\"Dropping fills where only the baseline is visible.\")\n",
    "        th = 0.5e-10\n",
    "        bl_mask = [(filtered_data_df[filtered_fillnum_df[\"fill\"].isin([fn])][src.get_column_names([24, 48],[rs])].max() -\n",
    "                 filtered_data_df[filtered_fillnum_df[\"fill\"].isin([fn])][src.get_column_names([24, 48],[rs])].min()).max() > th\n",
    "        for fn in filtered_fillnum_list]\n",
    "        filtered_fillnum_list_wo_bl = list(np.array(filtered_fillnum_list)[bl_mask])\n",
    "\n",
    "#sum up charge (integrate dQ/dt dt: \"integral\" to 1s so if sampling time is not 1s, the sums need to be scaled manually)\n",
    "        print(\"Summing up collected charge for remaining ({}) fills.\".format(len(filtered_fillnum_list_wo_bl)))\n",
    "        charge_sums = pd.DataFrame([filtered_data_df[filtered_fillnum_df[\"fill\"].isin([fn])].sum()\\\n",
    "                                    for fn in filtered_fillnum_list_wo_bl],\n",
    "                                   index=filtered_fillnum_list_wo_bl,\n",
    "                                   columns=filtered_data_df.columns.values)\n",
    "        \n",
    "#save summed up charge to excel file\n",
    "        if save_output:\n",
    "            charge_sums.to_excel(excel_out_dir+\"/charge_sums_{}_{}.xlsx\".format(year, month))\n",
    "            print(\"Summed charges saved to csv file.\")\n",
    "\n",
    "#create a df from fillnum list with the date range of data in each fill and the (approximate) sampling frequency in [ms]\n",
    "        fill_dates = pd.DataFrame([[fn,\n",
    "                                   min(fillnum_df[fillnum_df[\"fill\"]==fn].index.values),\n",
    "                                   max(fillnum_df[fillnum_df[\"fill\"]==fn].index.values),\n",
    "                                   pd.Timedelta(np.mean(fillnum_df[fillnum_df[\"fill\"]==fn].index.values[1:100]-\\\n",
    "                                   fillnum_df[fillnum_df[\"fill\"]==fn].index.values[:99]))]\n",
    "                                   for fn in filtered_fillnum_list_wo_bl],\n",
    "                                   columns=[\"fill\", \"data_start\", \"data_end\", \"sampling_time\"])\n",
    "        fill_dates[\"sampling_time\"] = fill_dates[\"sampling_time\"].astype('timedelta64[ms]')\n",
    "        fill_dates[\"sampling_time\"] = fill_dates[\"sampling_time\"]/1000\n",
    "\n",
    "#save fill dates and sampling freq. to excel file\n",
    "        if save_output:\n",
    "            fill_dates.to_excel(excel_out_dir+\"/fill_dates_{}_{}.xlsx\".format(year, month))\n",
    "            print(\"Fill data dates saved to csv file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "src.freeze_header(filtered_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours = dates.HourLocator(interval=48)\n",
    "h_fmt = dates.DateFormatter('%m/%d')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 6))\n",
    "plt.grid()\n",
    "\n",
    "for ch in [24, 48]:\n",
    "\n",
    "    # one column of dataframe\n",
    "    ch_fn_df = channels_data_df['CH' + str(ch) + 'RS9'].sort_index()\n",
    "    x = [pd.Timestamp(t) for t in ch_fn_df.index.values]\n",
    "    ax.plot(x, ch_fn_df.values, label=\"CH{}: {}\".format(ch, src.DETECTOR_NAMES[ch][0]), linewidth=1)\n",
    "\n",
    "    # Plot formatting\n",
    "    ax.xaxis.set_major_locator(hours)\n",
    "    ax.xaxis.set_major_formatter(h_fmt)\n",
    "    plt.yticks(fontsize=13)\n",
    "    plt.xticks(fontsize=13)\n",
    "    ax.set_title('CH 24, 48, RS 9', fontsize=19)\n",
    "    ax.set_ylabel('Signal current (A)', fontsize=19)\n",
    "    ax.set_xlabel('Time (UTC)', fontsize=19)\n",
    "    ax.set_yscale(\"log\")\n",
    "    plt.legend(loc=\"best\", prop={'size': 13})\n",
    "plt.savefig(\"../rs9_201810_brildata.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_to_save = channels_data_df[[\"CH24RS10\", \"CH48RS10\"]].sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_save.to_pickle(\"../pickle_data/201810_brildata_rs10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
